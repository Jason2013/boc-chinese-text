第12章 指令调度和再次调度
##########################

精简指令集计算（RISC）处理器采用简单的指令（这样保持硬件简单）来提高执行速率，还采用若干其它器件，来增加在固定时间间隔内可以执行的指令数目。

处理器是流水线化的。这意味着，单个指令在执行的时候被分解为若干个大约尺寸相同的小任务。一条指令的单个任务在一个装配线（称为流水线）上执行。流水线化提高了装配线的效率。当第一条指令完成第一个阶段时，第二条指令就可以开始执行了，或者被发出。在每个流水线上，每个指令周期可以发出一条指令。但是，一条指令发出之后，经过一到几个周期，也许没有完成求值。如果后面的指令试图使用前面指令计算的值，而前面的指令还没有完成所有流水线阶段，那么处理器会停顿，或者延迟发出第二条指令，直到第一条指令已经结束。为了提高性能，编译器会重排指令，以避免处理器停顿。[1]

[1当一个值还没有准备好时，早期的RISC处理器不会停顿。相反地，它们以垃圾数据为输入执行指令。编译器负责保证这样的执行不会发生。近期的处理器在等待操作数时都会停顿，因为有些指令不能确定等待的时间，特别是LOAD、乘法和除法指令，让调度变得困难。]

处理器在相同时间会发出多条指令。处理器会加载一小组指令，称为packet，分析这些指令之间的关系。如果指令不使用或修改小组中其它指令的操作数，那么可能在相同时间发出这些指令。这提高了性能，如果处理器有多个计算单元，例如整数算术单元和浮动算术单元。

处理器可能有多个整数单元和多个浮点数单元。这时，预取指令的packet容量更大，可能同时发出多条算术指令。不是所有算术单元是相同的。这时，编译器会重排指令，这样每个packet会有指令可以在不同的算术单元上执行。

具有这三个特征的处理器称为超标量处理器。今天大多数在用的处理器是超标量的。很多处理器有一个额外的特性，称为乱序（out-of-order）执行。这样的处理器会像上面描述的那样工作，而且当packet中前面的指令由于受限而不能执行时，允许执行packet中后面的指令。这里我们不讨论这个特性，因为编译器几乎不能做什么事情来加强处理器乱序执行，对于普通的超标量处理器来说，这是不重要的。

Digital Alpha 21164处理器是超标量处理器的一个例子。考虑它是怎么匹配上述标准的。首先，Alpha不是一个乱序执行的处理器。所有指令都是按照次序执行的；如果一条指令被延迟执行，跟在它后面的所有指令也会被延迟执行。

Alpha是管线化的。大多数整数算术单元的指令需要一个时钟周期；浮动指令需要四个时钟周期。以上法则的一些例外是条件赋值、LOAD、乘法和浮点除法指令。Alpha会尝试在每个时钟周期发出四条四字节的指令。指令的block必须对齐到一个16倍数的地址。如果地址不是16倍数，那么获取包含当前指令的packet，会忽略packet中开头的指令，这样减少了这个时钟周期内可以发出的指令数目。如果packet中的指令具有依赖关系，它们不能全部发出，就会发出packet开头部分的指令，直到不能被立即发出的第一条指令。

Alpha包含两个整数算术单元和两个浮点算术单元。两个整数算术单元可以执行大多数整数指令。例外如下，一个单元做移位操作，另一个单元做跳转操作。有一个浮点乘法单元和一个浮点加法单元。有些指令被两个单元共享。

理想地，Alpha在一个时钟周期发出四条指令。其中两条指令由整数算术单元执行。另外两条指令，其中一条由浮点乘法单元执行，最后一条指令由浮点加法单元执行。这些指令在packet中出现的次序是任意的。

Alpha还有别的特征，调度器必须予以考虑。考虑load操作。它们由整数算术单元执行；但是，从内存获取数据所需的时间取决于当前哪个高速缓存或内存单元包含此数据。

Alpha包含三个片上高速缓存：一个数据缓存，一个指令缓存，一个更大的辅助缓存。基本缓存容纳8K数据，组织为直接内存映射缓存，每个cache line的长度是32字节。如果数据在这个高速缓存中，一个load操作需要两个周期。指令缓存也是8K的片上缓存；但是，这里不讨论它。

辅助片上缓存存放指令和数据。它存放96K信息，组织为三路组相联高速缓存，每个cache line包含64字节数据。如果数据在这个高速缓存中，一个load操作需要九个周期，包括把数据搬运到基本缓存。

在Alpha系统上，通常有一个大的主板高速缓存。这个缓存容纳若干兆数据，组织为直接内存映射缓存，每个cache line容纳64字节数据。如果数据在这个缓存中，一个load操作需要二十个周期，包括把数据搬运到两个更高层级的缓存。

如果数据在内存中而不在缓存中，load操作就需要更长的时间：有时在一百个周期范围内，取决于涉及的系统。这个时间太长了，使得调度器模拟其准确的时间没有意义。编译器可以用两种方法处理它。编译器可以乐观地假设数据在其中一个缓存中，针对这种情形调度指令，或者编译器意识到这些load操作会消耗大量时间，尝试尽量把它们移动到早前的位置。

程序执行管线化的效果是这样的，程序中的指令在某个点发出，经过一定数量的时钟周期才得到结果。由于硬件优化，经过多少周期而获得结果值，可能取决于它怎么被使用，因此延迟（delay/latency）是计算一个值的指令和使用这个值的指令的函数。

指令调度phase重排被编译函数中的指令，消除尽可能多的停顿。有三种不同类型的调度器，根据它们尝试在多大的函数区域重排指令：

Block调度器在单个block内重排指令。程序流图的形式不会改变。一个block重排指令，和另一个block重排指令不相关，可能的例外是在block末尾计算的值（或在block开头使用的值）。

Trace调度器在一条简单路径上的block内重排指令。选择程序中执行最频繁的路径重排指令。指令可能从一个block移动到另一个block。事实上，指令可以移动到所计算的值保证未被使用的地方（推测执行）。重排这些更大的指令序列，可以发现更多机会来消除停顿。

软件流水线器重排并复制循环中的指令以消除停顿。软件流水线的结果是一个新的循环，原始循环中的多次迭代被合并成一次迭代同时计算。

对于超标量处理器来说，block调度是不够的。如果机器在每个时钟周期可以发出四条指令，那么一个周期的延迟意味着没法执行四次潜在的计算。编译器必须想办法把计算指令移动到一起，这样它们可以同时执行。大多数block是小的，编译器必须组合来自多个block或一个循环的多次迭代的计算指令。换句话说，编译器必须执行某种形式的trace调度和软件流水线。

到此刻为止，我们忽略了执行指令所需的时间和处理器发出指令的方式。指令调度phase重排指令以避免停顿。图12.1的Alpha指令序列计算表达式A = (B + C) + D * E，如果按照源语言所描述的次序执行指令，就会浪费两个周期。初始的load操作需要两个周期，从数据缓存中获取数据。可以利用这些周期执行后面的load操作，允许load和后续的乘法和加法重叠。

Figure 12.1 Instructions Before (left) and After (right) Scheduling

图12.1间接显示出三个顾虑。首先，原本的指令序列只用三个寄存器就可以执行。重排后的序列需要四个寄存器。重排指令可能增加所需寄存器的数目，让寄存器分配更困难。也有这样的情形，指令调度减小了所需寄存器的数目；但是，这很少见。总的来说，指令调度让寄存器分配更困难。

第二个问题是，当寄存器分配无法为所有临时变量分配物理寄存器时，会发生什么。寄存器分配器会插入store和load操作，把数据写到内存或者从内存读取数据。这些指令破坏了原始的指令调度，在寄存器分配之后可能需要重复指令调度。在第二次指令调度时，大多数临时变量已经赋予了物理寄存器，因此指令可移动的范围变小了。

第三个问题在上面的例子中是隐晦的。Alpha处理器同时可以发出四条指令。在这个例子中，可发出的指令总是不超过两条。很多周期没有指令可以发出，这样浪费了很多启动指令的机会（周期）。编译器怎样变形程序才能获得更多可发出指令？我们已经讨论了一种方法：循环展开。如果图12.1的代码是一个循环中的数组引用，那么循环的四次迭代可以同时执行，利用很多浪费的时钟周期。

12.1 指令调度phase的结构
*************************

编译器按组调度block：每个小组是支配者树的一条路径。注意，这是扩展的block的一般化。每个扩展的block是支配者树的子树，扩展的block构成的路径是支配者树的一条路径。一种trace调度方法在扩展的block上调度指令，因此这是那种技术的一般化。在调度block的时候，依次执行下面的操作：

1. 创建支配者树。支配者树是全局调度的基础数据结构。编译器用它找出可统一调度的路径。在调度指令的时候，它还会对指令执行值编码算法，在将被调度的路径上消除无用的计算。

2. 找出所有单block循环。对这些循环执行软件流水线。这涉及创建若干个block，以存放开始循环的指令、结束循环的指令和循环的副本，仅当执行的迭代很少时存放循环的副本。把这些block插入到支配者树中，原来的block标记为已调度单block路径的一个成员。

3. 为了执行指令调度，编译器需要知道在block和它支配的block之间有哪些临时变量被使用或定义。它们被称为IDEES和IUSE集合（不久我们会讨论如何计算它们）。编译器在开始调度之前计算它们。

4. 计算贯穿支配者树的路径或者trace，其上的block将被统一调度。有两种截然不同的组成trace的准则。如果执行频率是已知的，那么首先选择执行频率最高的路径，然后选择执行频率较小的路径。如果两个block具有相似的执行频率，那么更有可能与其前驱或后继合并的block被添加到路径中。

5. 现在对支配者树执行深度优先搜索。当到达开始一个trace的block时，调度这个trace。随着编译器遍历支配者树，它执行值编码算法，以找出重复的指令。重复的指令可以被删除，不需要调度。调度分成两个部分：计算指令之间的冲突图（interference graph），然后调整指令次序，让尽可能多的指令重叠执行。

和其它trace调度的方法不同的是，这个算法处理流图中的临时变量。后面会分配寄存器。在寄存器分配之后执行指令调度，每个trace是一个block，因此指令调度只发生在一个block之内。这时，只有那些插入了新指令的block需要再次调度。

12.2 Phase次序
***************

调度器执行两次。它跟在限制资源phase之后，所以我们知道，在程序中任意的点，有足够的寄存器存放所有的值。它在寄存器分配之前，所以还存在临时变量。它重排程序中的指令，生成相同程序的一个正确表示。在寄存器分配之后，调度器可能被再次调用，如果程序中插入了挤出（spill）操作。注意，窥孔优化在调度前执行。这样，指令调度phase附近的phase执行序列如图12.2所示。

指令调度发生在临时变量被绑定物理寄存器之前，前后移动指令的自由度相对更大。这可能会增加程序中每个点的活跃寄存器的数目。因此，必须约束调度器，在程序中的每个点，不让所需寄存器的数目增加到超过可用寄存器的数目。如果这对指令调度器限制得太多，我们将改变限制资源phase，进一步减小寄存器压力。当我们测试真实程序时，可以实验性地做这件事。

Figure 12.2 Sequence of Phases Involving Scheduling

指令调度可以为窥孔优化创造机会。对于访问相同位置的load和store操作，它可以移动它们，让它们相邻。因此，当调度器调度指令的时候，它必须准备好作一些形式受限的窥孔优化。执行寄存器分配之后，可以再次调用指令调度器，如果寄存器分配器生成了新的指令。如果分配寄存器的时候没有发生寄存器挤出（spilling），就没有必要执行第二次指令调度。

12.3 例子
***************

这里给出两个例子，来说明指令调度。首先，图12.3是可运行例子的内层循环。我们会调度这个循环体，提高一些性能，即使循环包含的指令不多。这是真实程序中很多循环的典型情况。

图12.4给出了相应的调度后的流图片段。循环中的所有store操作被移走了，superblock[2]转换把指令复制到了循环的末尾，以改善指令调度。

[2 Superblock调度在附录B中讨论。]

图12.5的例子有两个用途。编译器会软件流水线化这个循环，重叠多次迭代的执行。除了展示软件流水线，我们会用这个例子说明编译器将如何编译一个未作软件流水线化的循环。这样的循环可能会被展开，为了增加可以调度的指令。

Figure 12.3 Inner Loop of Example

Figure 12.4 Instructions in the inner Loop

Figure 12.5 Vectorizable Loop

图12.6给出了循环被软件流水线化时前面的编译器phase产生的指令。循环体包含一次循环迭代的指令。图12.7给出了假设循环不会被软件流水线化时所生成的指令。循环按照四次被展开，于是有些计算可以重叠。在这个例子中，编译器可能实际上按照四次以上展开循环；但是，作为一个例子，展开得更多没有意义。

Figure 12.6 Instructions for Vectorizable Loop

Figure 12.7 Unrolled Loop

在描述调度算法本身之前，我们来讨论五个话题，它们构成了调度的基础：

编译器不是在单个block中调度指令，而是在一组block中调度指令，这组block称为trace。首先编译器必须计算trace。然后调度trace中的指令，就像这些指令来自单个block。

如同一会你将看到的，trace不必是流图中顺序相邻的block。当它们不相邻时，编译器必须计算这样的临时变量，它们在trace中的多个block之间被使用或定义。

当trace和block间的信息是已知的时候，编译器会计算一种称为冲突图（interference graph）的数据结构，它描述哪些指令必须在其它指令之前求值，必须提前多长时间发出这些优先的指令。

就在指令被调度之前，编译器必须为每条指令估算从它开始执行到trace的末尾需要多少个时钟周期。这被称为关键路径信息，调度指令时会根据该信息选择指令。

在调度指令的时候，编译器模拟指令的执行，在每个执行周期跟踪记录处理器的哪些功能单元是忙碌的。跟踪的方法是维护一组状态信息，在每个周期更新它。预先计算功能单元所能达到的所有状态，将此表达为一个有限状态机，这样做更高效。更新状态，然后规约到一个状态转移。

我们将依次讨论这些话题，然后在结束的时候给出调度算法。

12.4 计算trace
***************

同时调度多个block的想法以trace调度的形式流行开来，trace调度是Fisher（1981）提出的。他注意到，大多数程序的一部分block比其它block更频繁地被执行。如果我们选择一个这样的block然后扩展它，添加它前面的block和后面的block，形成一条block的路径，那么我们可以一起调度这些block中的所有指令。当然，编译器必须插入指令以修复跳转指令的效果，包括跳入和跳出这条路径。

Trace调度表现良好，但是它有一个严重的弱点。这些为了修复跳入和跳出trace而插入的指令称为补偿代码，它们的数量可以很大，它们本身可能没有经过良好的调度。因此，具有单个主导trace的流图会得到良好的调度（大部分时间消耗在单个trace中）。但是，如果流图有多个重要的trace，或者找不出单个主导trace，调度的效果就没有那么好，因为补偿代码会让程序变慢。

Freudenberger, Gross和Lowney（1994）注意到，如果选择这样一个trace，不存在从trace外的block到trace的跳转分支，trace中的block是trace中唯一的另一个block的后继节点，那么可以消除大部分补偿代码。消除了大部分补偿代码，这个算法给出的性能和通用的trace算法几乎一样好。这些trace的另一个名字是扩展的block（extended block）。

| **定义**
| *扩展的block：*

流图中的扩展的block是满足下列条件的一组block：

在扩展的block中存在单个block B0，它在扩展的block中没有前驱节点。它所有的前驱节点出现在扩展的block之外。

在扩展的block中，每个除B0之外的block B都有单个前驱节点，这个前驱节点是扩展的block的成员。

换句话说，扩展的block是流图中的一棵block的树。Lowney建议，trace取扩展的block中的一条路径。

本调度器是基于这种想法的一般化，Sweany和Beaty（1992）提出了这种想法，后来Huber（1995）改进了它。Sweany选择支配者树中的路径作为trace。一个trace由一个block序列组成，其中每个block是下一个block的直接支配者。然后，调度这个trace，就像调度一个block的指令。在这个trace中向前或向后移动指令，这样有些指令可能被移动到执行频度较小的点，或者被移动到其执行时间可以被隐藏的位置。

将Sweany的准则应用于扩展的block。扩展的block中的每个block要么是入口block，要么在扩展的block中受它的前驱节点支配。然而，Sweany的trace定义允许其它可能的trace。考虑程序中的一个结构化的if语句。如果两个可选的分支具有几乎相等的频度，那么构建这样一个trace可能更好，它由开头的分支语句和末尾的汇合语句组成。

这种指令移动和优化器中的代码移动有何不同？优化器移动指令是受限的，它不能把指令移动到任意远的地方：它仅仅把指令移动到一个稍后总是将被使用的点，它不能把指令移动到这样一个点，在那里执行频度可能会增加，计算和使用之间的指令序列被最小化。指令调度器不会受到这样的限制。它可以把指令移动到一个不保证被使用的点，只要指令没有代价，寄存器压力不过量。

| **定义**
| *Trace：*

一个trace是这样的block序列B1, B2, ..., Bn，其中对于每个1 < i <= n，block Bi-1直接支配Bi。就是说，一个trace是支配者树中的一条路径。

编译器会把流图划分成一个个分离的trace。第一个被构造的trace应该代表执行最频繁的block，按某种方式被展开以改善这些block的执行。下一个最重要的trace从余下的block中构造，依此类推。编译器使用怎样的标准来选择trace的block呢？它需要考虑下面的因素：

这个trace应该包含还不属于任何trace的执行最频繁的block B。选择是基于频度信息的。有三种方法可收集此信息：统计，静态频度信息估计（如Ball和Larus（1992）的方法），和最内层循环粗略估计（考虑最内层循环执行频度最高，分支具有相等的可能）。这个block B被称为trace的锚点，因为trace完全由这个元素的选择决定。我们很快会看到，锚点不是trace的入口点。

考虑B的后继节点S，B是它们的唯一前驱节点，它们不属于别的trace。选择S中执行频度最高的节点。必然地，这个执行频度小于B的执行频度。将S纳入trace，对S的后继节点递归重复这个过程。这个过程的效果是将从B开始的扩展的block中执行最频繁的路径纳入trace。

再考虑锚点B的直接支配节点D。如果它还不属于一个trace，也不嵌套于跟B不相关的一个循环，就把D纳入trace。由于B具有最高频度，D的频度不会高于B；但是，它可能嵌入于一个不包含B的循环。这时不要添加D。对D的直接支配节点重复这个过程，以此类推。

如果在B处没有后继节点可用于扩展trace，支配者树中B的一个孩子节点也是B的后支配节点，并且它的执行频率和B一样，就把这个后支配节点也包含进来。

如果trace超过（实验决定的）一个固定的尺寸，就终止它。这个尺寸应该按照指令数量统计。有些调度算法不与trace的尺寸成线性，因此避免生成太长的trace。反过来，一个长的trace已经存在显著数量的指令重叠，因此再增加trace的尺寸，几乎不会带来益处。

给定这些条件，计算trace的算法是简单明了的，如图12.8所示。构造一个按执行频率排序的block优先级队列。利用这个队列找出trace的锚点，然后依照上面提到的规则扩展它。向后扫描，包含支配者节点，直到必须停止trace。这给出了入口点。现在从锚点开始向前扫描，包含扩展的block的一条路径，或者一个后支配者节点。这些规则是灵活的。trace的最优选择取决于用户的编程风格和源语言的最优编程风格，因此准备好修改此代码，以满足这些需求。

<Figure 12.8 Calculating Traces>

编译器需要一种命名trace的方法。编译器把trace的入口block用作名字。每个block有一个属性trace(B)，它要么是NULL，由于block还未插入到一个trace，要么是trace的入口block。有了这个属性，就能轻松找出trace中的所有block。trace由一组block组成，它们构成支配者树中的从trace入口block开始的一条路径。简单地向下扫描这棵树，查看每个孩子节点。如果一个孩子节点的属性值和trace相同，那么trace包含这个孩子。如果没有孩子节点的属性值和它的父亲节点相同，那么trace终止了。

注意，我们用双竖线，|B|，表示B中的指令数量。这种表示法是有道理的，因为在数学中双竖线用于表示基数。

图12.9给出了将锚点的支配者添加到trace的决定过程。任意支配者（编译器必须在树的根停下来），如果它们不在trace中，就添加它们。如果trace太长了，就终止它。编译器还要检查支配者是否在一个循环中，而这个循环不直接或间接包含锚点。支配者位于外层循环是适合的，而位于不直接或间接包含锚点的循环是不适合的。

<Figure 12.9 Determining Whether Dominators Can Be Added to a Trace>

<Figure 12.10 Determining Whether a Successor Can Be Added to a Trace>

图12.10的算法用于扩展trace，从锚点开始扩展为扩展的block。找到一个后继节点，它只有一个前驱节点。选择执行频率最高的后继节点，它就是下一个添加到trace的block。

现在考虑我们在本书中一直使用的程序例子。我们使用流图，但是不构造超级block。构造超级block能生成更好的trace，那是将来讨论的话题。假设每个循环被执行100次，那么内层循环实际上被执行了近10000次。假设在每个循环中最大值改变了大约10次，因此block B6的执行次数是1000次（见表12.1）。

编译器构造block的优先级队列，选择其中一个执行最频繁的block。这里的选择不是唯一的。一种可能是会首先选择block B3。然后扫描这个block的直接支配节点，得到第一个trace {B0, B1, B2, B3}。下一个trace将是单个block {B6}。然后block {B4}构成一个trace，{B5}是最后一个trace。

<Table 12.1 Hypothetical Frequencies>

另一种可能是选择block B2作为锚点来构造第一个trace。添加支配节点，添加扩展的block的后继节点。这给出了第一个trace {B0, B1, B2, B6}。然后{B3}自身会构成一个trace，{B4}和{B5}也是。

12.5 预计算资源信息
**********************

此调度器处理trace，它们是穿过支配者树的路径。在一个block和它的支配者之间，可能有多个block。编译器必须知道哪些临时变量和内存位置在这些block中被使用或修改。

12.5.1 定义和使用信息
=====================

调度器选择一个block序列B1, B2, ..., BN，其中每个block是它的后继节点的直接支配者。然后，一起调度这些block，可能将某个计算从一个block移动到前面的或者后面的block。为此，编译器必须知道哪些临时变量在这两个block之间被修改或使用。这里所用的算法以Reif和Lewis（1978）的算法为基础，Sweany和Beaty（1992）为指令调度改造了它。

| **定义**
| *OUT：*

对于每个block B，OUT(B)是执行B过程中被修改的临时变量的集合。

| **定义**
| *IDEFS：*

对于每个block B，IDEFS(B)是从IDOM(B)到B的某条路径上被定义的临时变量的集合。这不包括发生在B或IDOM(B)中的定义。

在图12.11中，IDEFS(B4)包括T2和T3，但是不包括T1和T4。它包括T2和T3，因为它们是在从B1到B4的路径上被定义的，而B1是B4的直接支配者。

<Figure 12.11 Flow Graph for IDEFS Compuation>

除了定义，使用也存在类似的信息集合。思想是相同的，后面我们会看到的计算方法也是相同的。唯一不同的是，被检测的是作为操作数的临时变量和变量的使用，而不是指令的结果。

| **定义**
| *IUSE：*

对于每个block B，IUSE(B)是从IDOM(B)到B的某条路径上作为操作数被使用的临时变量的集合。这不包括出现在B或IDOM(B)中的使用。

12.5.2 计算指令干涉信息
=======================

两个观察（observation）和一个数据结构说明了计算IDEFS和IUSE集合的技术。考虑从B的支配者到B的任意路径，IDOM(B) = B0, ..., Bn = B。注意每个Bi都受IDOM(B)的支配。

开始遍历以IDOM(B)开始的路径。在流图中B1必须是IDOM(B)的后继节点。这意味着IDOM(B)是B1的直接支配者。将B1标记为block Z1。继续遍历路径。起初，block（可能为空集）受Z1支配，但是最终要么到达了路径的末尾，要么找到了一个不受Z1支配的block。将该block称为Z2。断言IDOM(B)也是Z2的直接支配者。它受IDOM(B)支配，而不受路径上IDOM(B)之后任意其它block支配，因此它的直接支配者肯定是IDOM(B)。继续遍历，直到找到一个不受Z2支配的block，将它称为Z3。完成整个过程，找到该路径上的一个block序列Z1, ..., Zm，其中每个block在支配者树中是IDOM(B)的一个孩子节点。我们所要做的是找出每个在Zi和Zi+1之间的程序片段被修改的临时变量。我们即将看到，根据此信息，我们能计算出IDEFS(Zi)集合。

另一个观察告诉我们如何计算在Zi和Zi+1之间被修改的临时变量。考虑Zi+1。在流图中，我们知道它的每个前驱节点。其中一个前驱节点是路径上Zi+1之前的block。这个前驱节点受Zi支配。如果编译器知道受Zi支配的所有block的IDEFS信息，它就能够计算出从Zi到这个前驱节点的任意路径上被修改的临时变量集合（然后结合前驱节点的OUT信息，得到从Zi到Zi+1的信息）。

在描述这个计算方法之前，编译器需要一个这样的公式，它将IDEFS和在两个block P0和Pr之间可能被修改的临时变量的集合关联起来，其中P0支配Pr。考虑block序列P0, ..., Pr，其中Pi+1是Pi的直接支配者。在P0到Pr之间的任意路径包括所有这些block，而IDEFS的定义表明，在它们之间的任意路径上可能被修改的临时变量的集合，DEFS，必须满足下面的等式：

DEFS(P0, Pr) = IDEFS(Pr) . IDEFS(Pi) . OUT(Pi)

我们有基本的信息。编译器如何将基本的信息组织成一个算法？首先，编译器必须按照支配者树自底向上计算这些信息：为了计算支配者block的信息，需要被支配的block的信息。由于IDEFS的定义方式和前一个观察，这个观察就是支配者树中一个节点的孩子的信息可以影响其它孩子的信息，一个节点的所有孩子的信息是同时计算的。

编译器需要知道DEFS(Zi, P)，其中P是Zi+1的前驱节点。此信息难于高效地存储。存储使用UNION/FIND算法。考虑一个block B0，它是当前正在处理的block。假设Z1到Zn是支配者树中B0的孩子。这样，每个受B0支配的block，是以Zi为根节点的子树的一个成员。如果有一个block P，它是同一路径上Zi+1的前驱节点，就可以从P开始沿着支配者树向上走，到达B0相应的孩子，它是树的根节点。在此遍历过程中，我们可以利用上面的公式计算DEFS(Zi, P)。结合OUT(P)，我们就可以计算在Zi和Zi+1之间可能被修改的临时变量。这是我们需要的信息。

但是，这样的树遍历是低效的。于是，创建一个影子数据结构，在遍历树的时候它包含相同的信息。在遍历过程中，此数据结构被折叠（collapse）。此数据结构基于UNION/FIND树，添加EVAL操作以计算集合。下面介绍它是如何被构造的。当处理一个block的时候，把它添加到UNION/FIND结构，其中这个划分（partition）的代表是已经处理的子树的根节点block，子树中所有的block都受这个代表支配。当然，会发生标准的UNION/FIND折叠，使得该树比实际的支配者树更薄。此UNION/FIND结构中的边关联此结构中父节点和子节点之间的DEFS。当折叠发生时，DEFS集合被更新，以表示新的父亲和孩子。当EVAL被调用时，发生折叠，结果DEFS作为值被返回。

现在我们的算法差不多成形了，除了为特定节点的孩子计算IDEFS。之前的讨论告诉我们什么？我们可以把B0的孩子看作一个新的图，其中在两个孩子之间有一条边，如果有一条不经过父节点的边，从一个孩子到另一个孩子。给定这个新的图，IDEFS中临时变量的集合变成从图的根节点（它们是父节点的直接后继孩子节点）到某个节点的任意路径上被修改的临时变量的集合。为此，可以按照拓扑排序这些孩子。当然，会有强连通区域。这意味着任意的路径会穿过强连通区域，因此必须计算在一个强连通区域内被修改的所有临时变量的联合。

图12.12给出了执行上述计算的算法。查看每个孩子的前驱节点，找出支配这个前驱节点的别的孩子节点，这样构造孩子节点Zs的图。这确定了两个孩子节点之间的边。如之前指出的那样，向上遍历支配者树可以做到这个事情。相反，这个事情是由UNION/FIND算法做到的，因此路径可能被折叠。然后计算强连通分量，按照反向后序来排序其中的节点。这样达到了拓扑排序的效果。前驱节点出现在后继节点之前，除了强连通区域。

由于一条路径可以经过强连通区域任意次，一个强连通区域的作用是其中的block的作用的联合。对于单个block，前驱节点和当前block之间没有作用。已经计算了概要的作用，此信息被添加到已经为前驱节点计算的信息中，以指示在这样的路径上可以计算什么，即从直接支配节点开始穿过一个它的后继节点的路径，这个后继节点也是当前节点的一个孩子（或根）。然后，此信息被添加到支配者树以存储结果。

<Figure 12.12 Algorithm for IDEFS>

图12.13给出了实现UNION/FIND和EVAL所需的支持函数。因为文献中几乎不使用EVAL操作，所以把它们包括进来了。实现它们需要两个属性。DEFS表示在父节点和孩子节点之间被改变的临时变量的集合；此信息存储在孩子节点那里。FindParent给出一个block的父节点。如果它是空，那么这是当前树的根。

<Figure 12.13 Algorithms for UNION/FIND/EVAL>

初始化简单地将所有FindParent属性设置为空。DEFS属性不需要初始化，因为它只有在被设置之后才会被使用。FIND操作向上遍历树，找出树的根。此事一旦发生，就利用折叠函数折叠这棵树，以缩短将来的遍历过程。

UNION操作有一个固定的作为父节点的block。保证输入给它的两个block的FindParent属性是空，因此不会发生折叠。其它属性是在父节点和子节点之间被修改的block集合，被简单地存储在数据结构中。

EVAL操作利用FIND找出根节点。此时会发生一次折叠（在FIND中）。因此，EVAL简单地返回存储的数据，此数据已经被更新为在根（现在为父节点）和当前block之间。

上述内容如此复杂，有必要给出一个例子。考虑一直在用的例子（回顾图2.1），考虑它普通的流图。我们将处理单个临时变量。在这个案例中，我们可以把它看作布尔值而不是集合：如果临时变量在集合中，那么值为真。注意，block B1支配block B2和block B4。假设一个临时变量在block B6中被修改。IDEFS(B4)是什么？

在处理block B1之前（它计算IDEFS(B4)的值），此算法主要处理B2（它计算IDEFS(B3)和IDEFS(B6)的值）。block B3和B6构成一个图，B6处在B3的上游。当应用此算法的时候，OUT(B6)的值被添加到IDEFS(B3)中，因此IDEFS(B3)为真。

现在，对B1应用此算法，计算IDEFS(B4)和IDEFS(B2)的值。B4的一个前驱节点是B3，它受B2支配，因此在子节点构成的图中，B2处在B4的上游。在为B4计算IDEFS集合时，检查它的前驱节点B3，我们发现IDEFS(B3)为真，所以IDEFS(B4)为真。

此博弈算法可用于计算IUSE集合，利用被用作操作数的临时变量的IN集合，而不是被修改的临时变量的OUT集合。

12.6 指令干涉图
***************

现在，编译器已经确定了要调度的指令集合，构建了调度中用到的数据结构。[3]指令干涉图记录了排序指令的限制。为每个trace构建干涉图，记录哪些指令必须在其它指令之前发出，必须提前多少时钟周期发出，这样当它们被后面的指令使用时，其值是可用的（见图12.14）。

[3 注意我说了”用到的“而非”需要的“。不构建干涉图而作指令调度是可能的。反过来，跟踪指令计算操作数，跟踪它们的位置，这样可以隐式地构建干涉图。构建干涉图会更容易更有效，尽管它消耗时间和空间。]

<Figure 12.14 Computing the Interference Graph>

| **定义**
| *干涉图：*

给定一个trace，它包含block {B0, ..., Bn}，它的指令干涉图是一个有向无环图。在该图中存在三种不同类型的节点：

* trace中的每条指令是图中的一个节点。它们是干涉图的基本元素。

* trace中的每个block B有一个Block Start节点，它们被引用为Block_Start(B)。这个节点被用来决定一个block从何处开始。它还携带必要的依赖信息，用以阻止这样的指令排序，它可能导致以后将被使用的数据被破坏掉。

* trace中的每个block B有一个Block End节点，它们被引用为Block_End(B)。结合Block Start节点，它被用来决定一个block有哪些指令，并且携带必要的依赖信息，用以阻止错误的指令排序。

在两个节点之间的边(Tail, Head)表明在最终的指令次序中Tail必须处在Head的上游。在两个节点之间没有边意味着它们的次序是任意的。每条边会标注一个整数*delay((Tail), Head)*，指示从Tail发出到Head发出之间至少间隔多少个时钟周期。如果延迟是1，那么Head可能在Tail随后的时钟周期发出。延迟为0是可能的。这通常意味着存在专用的硬件，相比正常的管线时序，它让一条指令的值更快地可被另一条指令使用。

何时在两个节点之间会有一条边？有两个必要的条件。在原始的指令次序中，Tail必须处在Head的上游；就是说，Tail在Head之前被执行。第二，两条指令必须使用或者定义相同的资源。有四种情况：

* 真依赖：如果Tail修改了某个资源，后面Head会使用这个资源，那么这是一个真依赖。在两个节点之间存在一条边，它的延迟数值指示Tail完成修改资源所需的时间长度。延迟的长度依赖于Tail和Head，因为对于不同的指令对，资源变为可用所需的时间是不同的。

* 反依赖：如果Tail使用了某个资源，后面Head会修改这个资源，那么这是一个反依赖。不允许改变指令的次序：如果Head在Tail前面发出，那么Tail需要的值会被破坏掉。通常延迟是1，表明仅仅存储和载入的次序是重要的；然而，架构可能给定一个不同的延迟。在Alpha 21164上，在一个STORE和一个LOAD指令之间的一条反依赖边的延迟是3，因为访问刚刚被存储的数据是更困难的。

* 输出依赖：如果Tail和Head修改相同的资源，那么必须保持原始的次序，这样后面的节点会得到该资源被Head修改后的值。通常延迟是1，表明仅仅次序是有关的。

* 输入依赖：如果Tail和Head都使用某个资源而不修改它，那么它们的次序是无限制的。因为指令的次序是任意的，所以不会创建边。

一个资源是任意表达程序执行状态改变的量。因此，每个临时变量是一个资源。于是，从求值一个临时变量的指令到使用这个临时变量的每条指令之间，会有一条边。从求值一个临时变量的指令到求值相同临时变量的下一条指令之间，会有一条边。从使用一个临时变量的每条指令到求值相同临时变量的下一条指令之间，会有一条边。

如果目标机器具有条件码，那么条件码是一个资源。处理它们，像处理临时变量。如果指令集普遍地设置条件码，像有些复杂指令集计算（CISC）架构，那么应该特殊处理条件码，因为干涉图的尺寸会特别大。在大多数RISC架构中，只有一些指令设置条件码（如果存在条件码），一些指令读取条件码。这时，将条件码处理为指令的隐式操作数或结果，就像临时变量处理为实际的参数那样。

根据LOAD和STORE指令能够引用的内存区域为它们计算干涉信息。编译器可以识别的每个内存区域是一个资源；因此之前别名分析中用到的标签指示了单独的资源。载入和存储操作的边匹配出现的依赖类型：

在每个存储操作和每个后续对相同内存区域的载入操作之间，有一条边。如果编译器能够确定它们引用的内存区域不重叠，那么边是不必要的。编译器能够确定内存区域是否不同，如果地址是已知不同的（例如，地址是不同的常数），或者如果依赖分析器留下的信息表明存储和载入操作不会引用相同的内存位置。

在每个存储操作和每个后续存储操作之间，有一条边。像考虑存储和载入操作那样考虑这种情形。

在每个载入操作和后续相同内存区域的下一个存储操作之间，有一条边。当然，如果地址已知是不同的，那么边是不需要插入的。

不是所有的边都需要插入到图中。假设编译器在创建一条边(Tail, Head)，而图中已经存在两条边(Tail, Middle)和(Middle, Head)，且

delay((Tail, Head)) <= delay((Tail, Middle)) + delay((Middle, Head))

那么，新的边是不必要的。图中已经存在的边比新的边对指令次序施加更强的约束。容易识别下列三种此类情况：

* 考虑一个节点Head使用一个资源R。根据定义，肯定有这样一条边，它从每个修改R的上游节点到Head。编译器只需要记录从上一个修改R的上游节点到Head的边。修改R的节点集合在图中构成一组边，因为在每个这样的节点到下一个节点之间存在输出依赖。

* 输出依赖存在相似的情形。如果Head修改资源R，那么只需要一条从上游修改R的节点到Head的输出依赖边。

* 考虑一个节点Tail使用一个资源R。从Tail到下一个修改R的节点有一条边，记录一个反依赖；然而，不需要记录它和后面修改R的节点之间的反依赖，因为初始的反依赖和随后修改R的节点之间的输出依赖包含了此反依赖。

BlockStart(B)和BlockEnd(B)的干涉条件是什么？这些节点代表每个block的边界，因此编译器必须确保BlockStart节点出现在BlockEnd之前，支配者的BlockEnd节点出现在受支配block的BlockStart之前。另一种观察BlockStart节点的方式是这样的，它代表了出现在block之前且在支配者之后的所有指令。这些思想给出了BlockStart和BlockEnd的干涉条件：

在BlockStart(B)和BlockEnd(B)之间有一条干涉边，在BlockEnd(IDOM(B))和BlockStart(B)之间也有一条干涉边。这样，BlockStart和BlockEnd节点构成了图中的一个链表。实现它的时候，要么强制这些边存在，要么引入一个虚假的资源，让每个BlockStart节点写这个资源，让每个BlockEnd节点读这个资源。这会创建如上面提到的相同的边。

假装BlockStart(B)会读在B和IDOM(B)之间的指令读取的每个资源，假装它会写在B和IDOM(B)之间定义的每个资源。换句话说，让IUSE(B)作为BlockStart(B)使用的资源的集合，让IDEFS(B)作为BlockStart(B)定义的资源的集合。

12.7 计算指令优先级
********************

接下来，编译器会计算每条指令的优先级，换句话说，在调度trace中的指令时，优先级表示指令对于整体调度的重要程度。如果编译器延迟调度一些指令，所谓的关键指令，那么整个trace的执行时间会变长。其它指令在被调度时有更大的自由度。

一条指令的优先级，是指令的最小执行时间，从它调度后的位置到trace的末尾。考虑一条未调度的指令，从它将来调度后所处的点到trace的末尾，其时间间隔最长。如果我们延迟调度这条指令一个周期，整个trace的执行长度就增长了一个周期。因此，对调度来说最重要的指令是时间间隔最长的指令，从它开始执行到trace的末尾。编译器会计算冲突图（interference graph）中从指令到冲突图的叶子最长的路径，以此估算一条指令从发出到trace的末尾所需的时间间隔。

为什么这是一种估算？这个数字可能不准确，有两个主要的原因。求出最长的路径，作为时间的长度，这个方法假设有足够的功能单元，这样每条指令在任意时钟周期都可以被调度出去。它还假设每个功能单元在每个时钟周期是可用的。如果没有足够可用的功能单元，那么有些指令必须延迟一个周期。在有些Alpha处理器上，每四个周期只能发出一条乘法指令。

冲突图是无环的，最长路径可以被高效地计算出来，同时可以改进估算，以部分补偿这两个状况。编译器必须为每条指令计算属性priority(I)。可以用这样的方法计算这个属性，深度优先遍历整个冲突图，对于一个节点，先计算其后继的优先级，再计算它的优先级：

priority(J) = max {delay(J, I) + priority(I) | I ∈ Succ(J)}

不是所有指令都实现为简单管线化形式，因此必须用更复杂的公式。作为代表，考虑下面两个Alpha 21164中的情况：

* 整数乘法指令发出的频度不能超过每四到十二个周期一次，具体频度取决于指令和源操作数。每条乘法指令的延迟是八到十六个周期，因此乘法指令是部分管线化的。

* 在上一条浮点除法指令的结果出来之前，不能发出另一条浮点除法指令。

为了计算出一个更准确的优先级值，编译器必须计算由这些类型的指令导致的总的延迟。优先级不会小于这些值的其中一个。

编译器在计算这些总的值的时候，为指令依赖图中的每个节点维护临时变量属性multiply_latency和divide_latency。这些属性只用来计算优先级，计算优先级之后可以丢弃它们。

图12.15描述了这个算法。它是前面的讨论的一个直接的实现。这个算法的形式是一个深度优先搜索，先处理后继节点，再处理当前节点。利用我们讨论过的方法计算到达block末尾所需的最长时间。如果有其它应该包括的信息，也可以添加到这个算法中。

Figure 12.15 Computing Instruction Priority


12.8 模拟硬件
********************

一种观点将指令调度视作编译器模拟硬件，在每个时钟周期跟踪哪些功能单元在使用。然后它选择一条待发出的指令，根据当前哪些功能单元不在使用，并且在这条指令将来执行期间也不在使用。

为了进行这样的模拟，编译器需要一种追踪当前在使用功能单元的机制。编译器需要这样的一种高效的机制，最好一次简单的载入操作就能查明所有功能单元的当前状态。

历史上，功能单元的状态建模为一个布尔矩阵。每列代表一个时钟周期，其中第一列是当前时钟周期。每一行代表一个功能单元，如果它在任意列（也就是时钟周期）的值是真，那么这个功能单元在相应的时钟周期是在使用中。类似地，每条指令建模为一个相同形式的矩阵（时钟周期表示为列，功能单元表示为行）。如果一条指令在随后的周期不使用已经在使用的任意功能单元，换句话说，如果两个矩阵元素对元素相与（AND）的结果是一个零矩阵，就可以调度（选择发出）这条指令。如果可以调度这条指令，就可以这样更新状态，将之前的状态和被调度指令的状态相或（OR），得到新的状态。

Table 12.2 Hypothetical Machine State

最终，将没有指令能够被调度，因为功能单元是忙碌的，或者所依赖的前面的指令还在执行。这时，编译器将调度推进到下一个机器周期。这包括平移状态矩阵，这样第二列变成第一列，第三列变为第二列，等等。

为了解释这个方法，考虑一个假设的机器，它有一个整数功能单元、一个浮点加法单元和一个浮点乘法单元。假设我们在调度一个机器周期的中间，如表12.2中的机器状态所示。这个状态表明，我们已经调度了什么指令，它在使用整数单元。

表12.3-12.5代表单个指令类型的资源矩阵。多个指令可能共享功能用途的相同模式，因此它们可能结合在一起，让数据结构变小。

Table 12.3 Resource Matrix for Integer Operations

Table 12.4 Resource Matrix for Floating Add

Table 12.5 Resource Matrix for Floating Multiply

整数类型在一个周期完成任何运算，因此它在执行期间占用功能单元一个周期。浮点加法指令使用浮点单元两个周期，因此它不是完全管线化的。它只能间隔一个周期启动一条浮点指令。浮点乘法指令是完全管线化的。实际上，它应该被表示为多个功能单元在每个周期执行一个阶段；但是，只有浮点乘法器在使用这些功能单元，它们完全取决于管道中的第一个阶段，因此机器模型可以简化为只显示第一个阶段。

如果调度器首先调度一个浮点加法指令，然后在相同周期调度一个浮点乘法指令，那么机器状态看起来像表12.6那样。在这个周期，无法调度更多指令。

Table 12.6 End of One Cycle

Table 12.7 Machine State at Start of Next Cycle

为了开始下一个周期，机器将所有列向左平移一格，表明当前周期已经结束，下一个周期变成了当前时钟周期。这生成了表12.7中的状态。注意，机器可以发出一条整数指令或者一条浮点乘法。但是，不能发出浮点加法指令，因为相应的功能单元还是忙碌的。回想起浮点加法单元使用相同资源两次。

上面的描述是一种简化版本。有更多功能单元，不是所有功能单元都直接对应指令类型。例如，一个整数寄存器写的功能单元，将结果数据写到寄存器堆。还有，一些指令会使用 多个主要功能单元：一个复制整数到浮点数寄存器的指令，会涉及一些整数功能单元和一些浮点功能单元。

有这样一个问题，以这种方式计算机器的状态太费时间了，要求调度器使用专用的代码。本编译器使用一种Bala和Rubin（1996）提出的技术，来简化和加快处理状态。

12.8.1 预先计算机器状态机
=========================

主意是简单的。将机器状态表示为一个有限状态机。仔细看上面给出的描述。将每个机器状态矩阵视作有限状态机的一个状态。将每种指令类型视作词汇表的一个词，在词的作用下，一个状态转移到下一个状态，表示为矩阵相或（OR），如上面提到的那样。这给出了一个非确定性有限状态机。构建和它相关联的确定性有限状态机，我们就可以使用这个状态机而不是矩阵。这样，所有状态转移被简化为查询一个矩阵。

这个想法有一个问题。状态的数量可能很大：成千上万。这使得有限状态机需要巨大的存储。然而，Bala和Rubin注意到，处理器有着非常规则的结构。整数单元几乎和单个浮点单元无关。是时候审视有限状态机的向量积了。考虑有两个状态机，其状态是S1和S2，那么我们可以建立向量积有限状态机(S1, S2)，它是由S1和S2构成的有序的状态对。执行从一个状态到另一个状态的转移，等价于有序对的每个元素执行转移，取转移结果的有序对：也就是，τ(S1,S2) = (τ(S1),τ(S2))。

方案是这样的。将处理器划分成几个主要功能元素。每个部分构成一个机器。注意，所有指令是每个机器词汇表的一部分；整数指令很少改变浮点机器的状态，反过来也是。存储两个机器的状态，利用两个矩阵执行查找。每个主要功能部分的机器有数百个状态，而你在存储两个机器的状态。因此，状态可以表示为一对16位的数字。

注意，有限状态机可能是非确定性的。为什么？我们之前描述的构造不是确定性的吗？如果每个功能是单个功能单元，那么答案是肯定的。如果相同操作有多个单元（例如，多个整数功能单元），就会有相同指令类型到不同状态的多个转移。

这个机器的开始状态是什么？显然，一种开始状态是表示为值都是false的矩阵的状态；但是，还有两种其它状态类型：

* 当一个机器周期完成时，必须为下一个周期初始化机器状态。这要求将矩阵左移一列。因此，我们需要一个函数STATE_SHIFT(S)，它读取一个状态S，给出一个这样的状态，它的矩阵是将所有值都左移一列。这个函数的区间必须被考虑为调度下一个周期的开始状态。在内部，这个函数被表示为由S索引的一个向量，为下一个周期开始处的状态给出状态号。为了减小开始状态的数目，如果一个函数单元在一个给定的周期没有要调度的指令，就让调度器发出一条NOP指令。这意味着，所有初始函数单元将达到这样一种状态，它完成一个周期，而我们不需要为中间状态执行移位操作。

* 在block的开始处，编译器执行一个它的前驱block之后，必须估算一次机器的状态。这不需要准确：计算越精确，发生的停顿就越少。因为编译器不知道哪个block实际上是前驱block，它通过将多个状态矩阵或起来，根据每个前驱block结束处的状态构造一个状态。实际上，我们只需要考虑两个前驱block，因为我们可以连续地对剩余的前驱block成对地执行这个过程。因此，我们必须构造结束block的任意两个状态的或，由它们生成一个新的开始状态。我们需要一个函数COMBINE_PRED(S1, S2)，它接受两个矩阵的或作为参数，返回移位后的结果，作为block的第一条指令的开始状态。

我们已经概述了程序。所有的计算都是在编译器构建期间做的，这样机器中的代码包括代表转移函数的矩阵、COMBINE PRED函数、和一个代表STATE_SHIFT机器的向量。这非常像LEX和YACC中用到的表。

图12.16给出了算法的梗概。起初，机器的开始状态是完全空闲的。这个算法是按照矩阵编写的；但是，一个状态的矩阵存储一次，使用一个唯一的表示状态的整数来表示所有表中的矩阵，这些表被产生出来为编译器所用。

有一个等待列表，称为StateQueue，每个状态自创建之后就存放在那里。每个状态只进入队列一次，因为它同时进入StateTable和StateQueue，而且不会从StateTable移出。当一个状态被处理的时候，生成器尝试为每种可能的指令类别创建一个转移。

如果没有生成转移，那么对当前时钟周期来说机器满了，编译器必须生成一个转移，为下一个周期生成一个新的开始状态。为此，操作那个状态的矩阵，然后查看是否已经存在一个相应的状态。如果没有，也把它添加到状态集合中。

继续整个处理过程，直到所有状态已经被处理了，这样所有转移是已知的。算法执行结束后，一定找到了等价的确定性有限状态机。

12.8.2 向后查看已调度指令序列
=============================

针对有些调度优化和软件流水线，编译器有时想要向后扫描指令，为了向一个已调度列表插入指令。记录在资源矩阵中的机器状态和我们刚刚计算得到的状态告诉我们，是否存在一个空的位置，在那里可以插入一条指令。它并没有告诉我们，在那里插入一条指令是否会干涉后面某条已经被调度的指令。为此，我们需要反向有限状态机。

Figure 12.16 Generating State Machine

考虑相同的状态集合，但是按照反方向构建转移。这样我们得到一个十足的非确定性有限状态机，由此我们可以构建一个确定性有限状态机。调度一个block之后，我们对block运行反向状态机，赋予每条指令一对状态数字。前向状态数字指示将来可以出现的合法指令，后向状态数字指示过去可以出现的合法指令。

现在，我们有了在指令执行之前对机器状态的表示和在指令执行之后对机器状态的表示。我们为每条指令存储此信息。在指令调度和寄存器分配期间，为每条指令记录两个临时属性。ForwardState(I)是指令I执行之前机器的状态。BackwardState(I)是指令I之后其余指令的状态。

12.8.3 在调度时替换指令
=======================

正常的指令调度只需要ForwardState(I)执行表调度（list scheduling）。事实上，不需要将它存储为一个属性，因为编译器只需要当前的状态，它可以存储为一个全局变量。调度指令打乱原始顺序，有三种实例：

正常调度指令的时候，我们在一个时钟周期调度一条关键指令，必须确保block的最小长度。此后，能够在它之后调度的关键指令变少了，只要它们不会延迟这条关键指令的调度。可以这样调度它们，先调度下一条关键指令，然后在它之前插入其它指令。

在执行软件流水线时，编译器调度一条指令，会假装实际上在均匀间隔的后续周期调度相同指令的影子版本。编译器必须记录这样的事实，影子指令被安排在后面固定的点。这样，有些后面的指令必须在下一条当前指令之前被调度。

在寄存器分配期间，指令极少会挤出（spill）到内存。这需要插入载入和存储操作。为此，最好的办法是在调度好的指令序列中找出可以放置LOAD或者STORE指令的空的位置，然后直接在那里放置这些指令。

因此，我们需要知道在什么条件下一条指令可以被另一条指令替换。这包括在已调度序列的一个空位插入一条指令的可能性。

假设已调度序列的每个位置具有状态ForwardStarte(I)和BackwardState(I)，不管位置上有没有指令。于是，这个已调度序列可以被实现为一个足够大的数组，每条指令占据一个位置。开始时，将ForwardState和BackwardState属性初始化为每个机器的开始状态，指示所有资源矩阵都是空的。

下面考虑指令I可以被插入到位置IS的条件。能够在那个位置插入指令，意味着该指令和之前已经调度的所有指令都不冲突。这等同于有一个ForwardState(IS)的输出转移，因为只有在无冲突时我们才会创建转移。BackwardState(IS)属性指示是否存在已经调度的后续指令和I冲突。如果不存在后续指令和I冲突，那么在I处有一个合法的BackwardState(IS)的输出转移。

如果指令I可以被放置在位置IS处，那么必须更新位置的ForwardState和BackwardState属性。这涉及从位置IS向前重新计算ForwardState属性，从位置IS向后重新计算BackwardSate属性。这没感觉上那么耗时。因为我们在处理有限状态机，只要新计算的状态不同于之前存储的状态，我们只需要向前（或向后）扫描。

只有少量位置重新计算状态会出现不同。为什么？回想有限状态机的构建，它涉及资源矩阵和列位移。一旦已经向左移动了当前指令涉及的所有列，当前指令在状态机中是不可见的。换句话说，只会出现少量的位移（矩阵的列的最大数量）。在实践中，只需要少量迭代。

图12.17给出的伪代码概述了这个插入算法。它详细描述了上面的讨论。如果指令无法插入，就返回false。反之，插入指令并更新状态。

Figure 12.17 Inserting Instructions in Slots

12.9
********************